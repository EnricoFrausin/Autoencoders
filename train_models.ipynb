{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7771820b",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e526374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ea74f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from AE.models import AE_0\n",
    "from AE.train import train\n",
    "from AE.datasets import MNISTDigit2Dataset\n",
    "from AE.utils import get_binary_latent_frequencies, analyze_binary_frequencies\n",
    "from AE.plotter_functions import plot_original_vs_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f2f1083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizzo Apple Silicon GPU (MPS)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10d92bfb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Utilizzo Apple Silicon GPU (MPS)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Utilizzo NVIDIA GPU (CUDA)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Utilizzo la CPU\")\n",
    "\n",
    "device = torch.device(\"cpu\")  # Fallback to CPU if no GPU is available\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fa9424",
   "metadata": {},
   "source": [
    "# Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de3a7528",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da45cb3e",
   "metadata": {},
   "source": [
    "## MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eb36d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader_MNIST = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        '/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor()\n",
    "        ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    "    )\n",
    "\n",
    "val_loader_MNIST = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        '/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor()\n",
    "        ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9be5ba0",
   "metadata": {},
   "source": [
    "\n",
    "## ExtendedMNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92a257df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader_EMNIST = torch.utils.data.DataLoader(\n",
    "    datasets.EMNIST(\n",
    "        '/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data',\n",
    "        split='balanced',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor()\n",
    "        ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    "    )\n",
    "\n",
    "val_loader_EMNIST = torch.utils.data.DataLoader(\n",
    "    datasets.EMNIST(\n",
    "        '/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data',\n",
    "        split='balanced',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor()\n",
    "        ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0deb7f",
   "metadata": {},
   "source": [
    "\n",
    "## 2MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "802095a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5958 original samples of digit '2'\n",
      "Generated 60000 augmented samples\n",
      "Dataset size: 60000\n",
      "Image shape: torch.Size([1, 28, 28])\n",
      "Label: 2\n",
      "Batch images shape: torch.Size([64, 1, 28, 28])\n",
      "Batch labels shape: torch.Size([64])\n",
      "All labels are 2: True\n",
      "\n",
      "––––––––––––––––––––––––––––––––––––––––––––––––––––––\n",
      "\n",
      "Found 1032 original samples of digit '2'\n",
      "Generated 10000 augmented samples\n",
      "Dataset size: 60000\n",
      "Image shape: torch.Size([1, 28, 28])\n",
      "Label: 2\n",
      "All labels are 2: True\n",
      "Batch images shape: torch.Size([64, 1, 28, 28])\n",
      "Batch labels shape: torch.Size([64])\n",
      "All labels are 2: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_2MNIST_train = MNISTDigit2Dataset(train=True, download=True, target_size=60000)\n",
    "print(f\"Dataset size: {len(dataset_2MNIST_train)}\")\n",
    "print(f\"Image shape: {dataset_2MNIST_train[0][0].shape}\")\n",
    "print(f\"Label: {dataset_2MNIST_train[0][1]}\")\n",
    "train_loader_2MNIST = DataLoader(dataset_2MNIST_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "batch_images, batch_labels = next(iter(train_loader_2MNIST))\n",
    "print(f\"Batch images shape: {batch_images.shape}\")\n",
    "print(f\"Batch labels shape: {batch_labels.shape}\")\n",
    "print(f\"All labels are 2: {torch.all(batch_labels == 2)}\")\n",
    "\n",
    "print(\"\\n––––––––––––––––––––––––––––––––––––––––––––––––––––––\\n\")\n",
    "\n",
    "dataset_2MNIST_val = MNISTDigit2Dataset(train=False, download=True, target_size=10000)\n",
    "print(f\"Dataset size: {len(dataset_2MNIST_train)}\")\n",
    "print(f\"Image shape: {dataset_2MNIST_train[0][0].shape}\")\n",
    "print(f\"Label: {dataset_2MNIST_train[0][1]}\")\n",
    "print(f\"All labels are 2: {torch.all(batch_labels == 2)}\")\n",
    "val_loader_2MNIST = DataLoader(dataset_2MNIST_val, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"Batch images shape: {batch_images.shape}\")\n",
    "print(f\"Batch labels shape: {batch_labels.shape}\")\n",
    "print(f\"All labels are 2: {torch.all(batch_labels == 2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b137f72b",
   "metadata": {},
   "source": [
    "\n",
    "## FashionMNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e545536",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader_FashionMNIST = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        '/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor()\n",
    "        ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    "    )\n",
    "\n",
    "val_loader_FashionMNIST = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        '/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor()\n",
    "        ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0ab4c4",
   "metadata": {},
   "source": [
    "\n",
    "## OTHERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c223ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train over pureHFM\n",
    "\n",
    "dataset_HFM_train = Dataset_pureHFM(csv_file='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/pureHFM/512features/glog2_train60000.pt',\n",
    "                        root_dir='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/pureHFM')\n",
    "\n",
    "train_loader_pureHFM = DataLoader(\n",
    "    dataset_HFM_train,\n",
    "    batch_size=md.batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataset_HFM_val = Dataset_pureHFM(csv_file='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/pureHFM/512features/glog2_validation10000.pt',\n",
    "                            root_dir='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/pureHFM')\n",
    "\n",
    "val_loader_pureHFM = DataLoader(\n",
    "    dataset_HFM_val, # Importante: usa dataset_HFM_val qui, non dataset_HFM\n",
    "    batch_size=md.batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "## train over expandedHFM\n",
    "dataset_HFM_train = Dataset_HFM(csv_file='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/expandedHFM/16_1024features/2hl_glog2_train60000.pt',\n",
    "                        root_dir='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/pureHFM')\n",
    "\n",
    "train_loader_expandedHFM = DataLoader(\n",
    "    dataset_HFM_train,\n",
    "    batch_size=md.batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataset_HFM_val = Dataset_HFM(csv_file='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/expandedHFM/16_1024features/2hl_glog2_validation10000.pt',\n",
    "                            root_dir='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/pureHFM')\n",
    "\n",
    "val_loader_expandedHFM = DataLoader(\n",
    "    dataset_HFM_val, # Importante: usa dataset_HFM_val qui, non dataset_HFM\n",
    "    batch_size=md.batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "## train over expandedHFM 32-1024\n",
    "dataset_HFM_train = Dataset_HFM(csv_file='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/expandedHFM/32_1024features/2hl_glog2_train60000.pt',\n",
    "                        root_dir='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/pureHFM')\n",
    "\n",
    "train_loader_expandedHFM_32_1024 = DataLoader(\n",
    "    dataset_HFM_train,\n",
    "    batch_size=md.batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataset_HFM_val = Dataset_HFM(csv_file='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/expandedHFM/32_1024features/2hl_glog2_validation10000.pt',\n",
    "                            root_dir='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/pureHFM')\n",
    "\n",
    "val_loader_expandedHFM_32_1024 = DataLoader(\n",
    "    dataset_HFM_val, # Importante: usa dataset_HFM_val qui, non dataset_HFM\n",
    "    batch_size=md.batch_size,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc5dc6",
   "metadata": {},
   "source": [
    "# Autoencoders model 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffa9c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcebec4",
   "metadata": {},
   "source": [
    "\n",
    "## EMNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ab78264",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = train_loader_EMNIST\n",
    "val_loader = val_loader_EMNIST\n",
    "input_dim = 784\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9434c476",
   "metadata": {},
   "source": [
    "\n",
    "### 8 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0bac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = AE_0(input_dim=input_dim, latent_dim=8, decrease_rate=0.5, device=device, hidden_layers=1, output_activation_encoder=nn.Sigmoid).to(device)\n",
    "my_model.load_state_dict(torch.load('/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/models/EMNIST/ld8_ep15_dr05_1hl.pth', map_location=my_model.device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c9513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir='/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/runs/EMNIST/ld8_ep15_dr05_1hl')\n",
    "my_model = AE_0(input_dim=input_dim, latent_dim=8, decrease_rate=0.5, device=device, hidden_layers=1, output_activation_encoder=nn.Sigmoid).to(device)\n",
    "optimizer = optim.Adam(my_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "train(my_model, writer=writer, train_loader=train_loader, val_loader=val_loader, optimizer=optimizer, epochs=15)\n",
    "torch.save(my_model.state_dict(), '/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/models/EMNIST/ld8_ep15_dr05_1hl.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2018b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir='/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/runs/EMNIST/ld8_ep15_dr05_1hl_1')\n",
    "my_model = AE_0(input_dim=input_dim, latent_dim=8, decrease_rate=0.5, device=device, hidden_layers=1).to(device)\n",
    "optimizer = optim.Adam(my_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "train(my_model, writer=writer, train_loader=train_loader, val_loader=val_loader, optimizer=optimizer, epochs=15)\n",
    "torch.save(my_model.state_dict(), '/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/models/EMNIST/ld8_ep15_dr05_1hl_1.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ac8dda",
   "metadata": {},
   "source": [
    "# controlliamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1efa4531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "706848fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723ac936",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4ecf1c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = train_loader_MNIST\n",
    "val_loader = val_loader_MNIST\n",
    "input_dim = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "95f9de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956b52b9",
   "metadata": {},
   "source": [
    "## 8 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbeb9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/15, Average loss: 0.0006\n",
      "Epoch: 1/15, Average loss: 0.0004\n",
      "Epoch: 2/15, Average loss: 0.0004\n",
      "Epoch: 3/15, Average loss: 0.0004\n",
      "Epoch: 4/15, Average loss: 0.0004\n",
      "Epoch: 5/15, Average loss: 0.0004\n",
      "Epoch: 6/15, Average loss: 0.0004\n",
      "Epoch: 7/15, Average loss: 0.0004\n",
      "Epoch: 8/15, Average loss: 0.0004\n",
      "Epoch: 9/15, Average loss: 0.0004\n",
      "Epoch: 10/15, Average loss: 0.0004\n",
      "Epoch: 11/15, Average loss: 0.0004\n",
      "Epoch: 12/15, Average loss: 0.0004\n",
      "Epoch: 13/15, Average loss: 0.0004\n",
      "Epoch: 14/15, Average loss: 0.0004\n",
      "Training completed. Final training loss: 0.00039343795993675786, Validation loss: 0.0003899347236379981\n",
      "Epoch: 0/15, Average loss: 0.0006\n",
      "Epoch: 1/15, Average loss: 0.0004\n",
      "Epoch: 2/15, Average loss: 0.0004\n",
      "Epoch: 3/15, Average loss: 0.0004\n",
      "Epoch: 4/15, Average loss: 0.0004\n",
      "Epoch: 5/15, Average loss: 0.0004\n",
      "Epoch: 6/15, Average loss: 0.0004\n",
      "Epoch: 7/15, Average loss: 0.0004\n",
      "Epoch: 8/15, Average loss: 0.0004\n",
      "Epoch: 9/15, Average loss: 0.0004\n",
      "Epoch: 10/15, Average loss: 0.0004\n",
      "Epoch: 11/15, Average loss: 0.0003\n",
      "Epoch: 12/15, Average loss: 0.0003\n",
      "Epoch: 13/15, Average loss: 0.0003\n",
      "Epoch: 14/15, Average loss: 0.0003\n",
      "Training completed. Final training loss: 0.00034103141855448485, Validation loss: 0.00033711685836315154\n",
      "Epoch: 0/15, Average loss: 0.0008\n",
      "Epoch: 1/15, Average loss: 0.0006\n",
      "Epoch: 2/15, Average loss: 0.0005\n",
      "Epoch: 3/15, Average loss: 0.0005\n",
      "Epoch: 4/15, Average loss: 0.0005\n",
      "Epoch: 5/15, Average loss: 0.0004\n",
      "Epoch: 6/15, Average loss: 0.0004\n",
      "Epoch: 7/15, Average loss: 0.0004\n",
      "Epoch: 8/15, Average loss: 0.0004\n",
      "Epoch: 9/15, Average loss: 0.0004\n",
      "Epoch: 10/15, Average loss: 0.0004\n",
      "Epoch: 11/15, Average loss: 0.0004\n",
      "Epoch: 12/15, Average loss: 0.0004\n",
      "Epoch: 13/15, Average loss: 0.0004\n",
      "Epoch: 14/15, Average loss: 0.0004\n",
      "Training completed. Final training loss: 0.0003783856605490049, Validation loss: 0.00037727564200758934\n",
      "Epoch: 0/15, Average loss: 0.0009\n",
      "Epoch: 1/15, Average loss: 0.0007\n",
      "Epoch: 2/15, Average loss: 0.0006\n",
      "Epoch: 3/15, Average loss: 0.0005\n",
      "Epoch: 4/15, Average loss: 0.0005\n",
      "Epoch: 5/15, Average loss: 0.0005\n",
      "Epoch: 6/15, Average loss: 0.0005\n",
      "Epoch: 7/15, Average loss: 0.0005\n",
      "Epoch: 8/15, Average loss: 0.0004\n",
      "Epoch: 9/15, Average loss: 0.0004\n",
      "Epoch: 10/15, Average loss: 0.0004\n",
      "Epoch: 11/15, Average loss: 0.0004\n",
      "Epoch: 12/15, Average loss: 0.0004\n",
      "Epoch: 13/15, Average loss: 0.0004\n",
      "Epoch: 14/15, Average loss: 0.0004\n",
      "Training completed. Final training loss: 0.000413526304345578, Validation loss: 0.0004128978965803981\n",
      "Epoch: 0/15, Average loss: 0.0011\n",
      "Epoch: 1/15, Average loss: 0.0011\n",
      "Epoch: 2/15, Average loss: 0.0011\n",
      "Epoch: 3/15, Average loss: 0.0011\n",
      "Epoch: 4/15, Average loss: 0.0011\n",
      "Epoch: 5/15, Average loss: 0.0011\n",
      "Epoch: 6/15, Average loss: 0.0011\n",
      "Epoch: 7/15, Average loss: 0.0011\n",
      "Epoch: 8/15, Average loss: 0.0011\n",
      "Epoch: 9/15, Average loss: 0.0011\n",
      "Epoch: 10/15, Average loss: 0.0011\n",
      "Epoch: 11/15, Average loss: 0.0011\n",
      "Epoch: 12/15, Average loss: 0.0011\n",
      "Epoch: 13/15, Average loss: 0.0011\n",
      "Epoch: 14/15, Average loss: 0.0011\n",
      "Training completed. Final training loss: 0.0010522762250776093, Validation loss: 0.001060366228595376\n",
      "Epoch: 0/15, Average loss: 0.0011\n",
      "Epoch: 1/15, Average loss: 0.0011\n",
      "Epoch: 2/15, Average loss: 0.0011\n",
      "Epoch: 3/15, Average loss: 0.0011\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     38\u001b[39m writer = SummaryWriter(log_dir=\u001b[33m'\u001b[39m\u001b[33m/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/runs/MNIST/ld8_ep15_dr06_lr1e3_opeSigm_6hl\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     39\u001b[39m optimizer = optim.Adam(my_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m torch.save(my_model.state_dict(), \u001b[33m'\u001b[39m\u001b[33m/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/models/MNIST/ld8_ep15_dr06_lr1e3_opeSigm_6hl.pth\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# 7 hidden layers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:6\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, epochs, train_loader, val_loader, optimizer, writer, scheduler, save_tensorboard_parameters)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programmazione/Python_nn/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programmazione/Python_nn/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programmazione/Python_nn/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programmazione/Python_nn/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programmazione/Python_nn/.venv/lib/python3.11/site-packages/torchvision/datasets/mnist.py:139\u001b[39m, in \u001b[36mMNIST.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) -> Tuple[Any, Any]:\n\u001b[32m    132\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[33;03m        index (int): Index\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    137\u001b[39m \u001b[33;03m        tuple: (image, target) where target is index of the target class.\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     img, target = \u001b[38;5;28mself\u001b[39m.data[index], \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[32m    142\u001b[39m     \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[32m    143\u001b[39m     img = Image.fromarray(img.numpy(), mode=\u001b[33m\"\u001b[39m\u001b[33mL\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 1 hidden layer\n",
    "my_model = AE_0(input_dim=input_dim, latent_dim=8, decrease_rate=0.5, device=device, hidden_layers=1, output_activation_encoder=nn.Sigmoid, output_activation_decoder=None).to(device)\n",
    "writer = SummaryWriter(log_dir='/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/runs/MNIST/ld8_ep15_dr05_lr1e3_opeSigm_1hl')\n",
    "optimizer = optim.Adam(my_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "train(my_model, writer=writer, train_loader=train_loader, val_loader=val_loader, optimizer=optimizer, epochs=15)\n",
    "torch.save(my_model.state_dict(), '/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/models/MNIST/ld8_ep15_dr05_lr1e3_opeSigm_1hl.pth')\n",
    "\n",
    "# 2 hidden layers\n",
    "my_model = AE_0(input_dim=input_dim, latent_dim=8, decrease_rate=0.5, device=device, hidden_layers=2, output_activation_encoder=nn.Sigmoid, output_activation_decoder=None).to(device)\n",
    "writer = SummaryWriter(log_dir='/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/runs/MNIST/ld8_ep15_dr05_lr1e3_opeSigm_2hl')\n",
    "optimizer = optim.Adam(my_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "train(my_model, writer=writer, train_loader=train_loader, val_loader=val_loader, optimizer=optimizer, epochs=15)\n",
    "torch.save(my_model.state_dict(), '/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/models/MNIST/ld8_ep15_dr05_lr1e3_opeSigm_2hl.pth')\n",
    "\n",
    "# 3 hidden layers\n",
    "my_model = AE_0(input_dim=input_dim, latent_dim=8, decrease_rate=0.5, device=device, hidden_layers=3, output_activation_encoder=nn.Sigmoid, output_activation_decoder=None).to(device)\n",
    "writer = SummaryWriter(log_dir='/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/runs/MNIST/ld8_ep15_dr05_lr1e3_opeSigm_3hl')\n",
    "optimizer = optim.Adam(my_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "train(my_model, writer=writer, train_loader=train_loader, val_loader=val_loader, optimizer=optimizer, epochs=15)\n",
    "torch.save(my_model.state_dict(), '/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/models/MNIST/ld8_ep15_dr05_lr1e3_opeSigm_3hl.pth')\n",
    "\n",
    "# 4 hidden layers\n",
    "my_model = AE_0(input_dim=input_dim, latent_dim=8, decrease_rate=0.5, device=device, hidden_layers=4, output_activation_encoder=nn.Sigmoid, output_activation_decoder=None).to(device)\n",
    "writer = SummaryWriter(log_dir='/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/runs/MNIST/ld8_ep15_dr05_lr1e3_opeSigm_4hl')\n",
    "optimizer = optim.Adam(my_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "train(my_model, writer=writer, train_loader=train_loader, val_loader=val_loader, optimizer=optimizer, epochs=15)\n",
    "torch.save(my_model.state_dict(), '/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/models/MNIST/ld8_ep15_dr05_lr1e3_opeSigm_4hl.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1b127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/15, Average loss: 0.0010\n",
      "Epoch: 1/15, Average loss: 0.0009\n",
      "Epoch: 2/15, Average loss: 0.0008\n",
      "Epoch: 3/15, Average loss: 0.0008\n",
      "Epoch: 4/15, Average loss: 0.0008\n",
      "Epoch: 5/15, Average loss: 0.0007\n",
      "Epoch: 6/15, Average loss: 0.0007\n",
      "Epoch: 7/15, Average loss: 0.0007\n",
      "Epoch: 8/15, Average loss: 0.0007\n",
      "Epoch: 9/15, Average loss: 0.0007\n",
      "Epoch: 10/15, Average loss: 0.0007\n",
      "Epoch: 11/15, Average loss: 0.0007\n",
      "Epoch: 12/15, Average loss: 0.0007\n",
      "Epoch: 13/15, Average loss: 0.0007\n",
      "Epoch: 14/15, Average loss: 0.0007\n",
      "Training completed. Final training loss: 0.0006705451377977927, Validation loss: 0.0006723556384444237\n",
      "Epoch: 0/15, Average loss: 0.0011\n",
      "Epoch: 1/15, Average loss: 0.0011\n",
      "Epoch: 2/15, Average loss: 0.0011\n",
      "Epoch: 3/15, Average loss: 0.0011\n",
      "Epoch: 4/15, Average loss: 0.0011\n",
      "Epoch: 5/15, Average loss: 0.0011\n",
      "Epoch: 6/15, Average loss: 0.0011\n",
      "Epoch: 7/15, Average loss: 0.0011\n",
      "Epoch: 8/15, Average loss: 0.0011\n",
      "Epoch: 9/15, Average loss: 0.0011\n",
      "Epoch: 10/15, Average loss: 0.0011\n",
      "Epoch: 11/15, Average loss: 0.0011\n",
      "Epoch: 12/15, Average loss: 0.0011\n",
      "Epoch: 13/15, Average loss: 0.0011\n",
      "Epoch: 14/15, Average loss: 0.0011\n",
      "Training completed. Final training loss: 0.001052121254367133, Validation loss: 0.0010613720007240771\n",
      "Epoch: 0/15, Average loss: 0.0011\n",
      "Epoch: 1/15, Average loss: 0.0011\n",
      "Epoch: 2/15, Average loss: 0.0011\n",
      "Epoch: 3/15, Average loss: 0.0011\n",
      "Epoch: 4/15, Average loss: 0.0011\n",
      "Epoch: 5/15, Average loss: 0.0011\n",
      "Epoch: 6/15, Average loss: 0.0011\n",
      "Epoch: 7/15, Average loss: 0.0011\n",
      "Epoch: 8/15, Average loss: 0.0011\n",
      "Epoch: 9/15, Average loss: 0.0011\n",
      "Epoch: 10/15, Average loss: 0.0011\n",
      "Epoch: 11/15, Average loss: 0.0011\n",
      "Epoch: 12/15, Average loss: 0.0011\n",
      "Epoch: 13/15, Average loss: 0.0011\n",
      "Epoch: 14/15, Average loss: 0.0011\n",
      "Training completed. Final training loss: 0.0010521146930754185, Validation loss: 0.0010599195212125778\n"
     ]
    }
   ],
   "source": [
    "# 5 hidden layers\n",
    "learning_rate = 1e-4\n",
    "\n",
    "my_model = AE_0(input_dim=input_dim, latent_dim=8, decrease_rate=0.55, device=device, hidden_layers=5, output_activation_encoder=nn.Sigmoid, output_activation_decoder=None).to(device)\n",
    "writer = SummaryWriter(log_dir='/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/runs/MNIST/ld8_ep15_dr055_lr1e4_opeSigm_5hl')\n",
    "optimizer = optim.Adam(my_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "train(my_model, writer=writer, train_loader=train_loader, val_loader=val_loader, optimizer=optimizer, epochs=15)\n",
    "torch.save(my_model.state_dict(), '/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/models/MNIST/ld8_ep15_dr055_lr1e4_opeSigm_5hl.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d89bb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/15, Average loss: 0.0013\n",
      "Epoch: 1/15, Average loss: 0.0010\n",
      "Epoch: 2/15, Average loss: 0.0010\n",
      "Epoch: 3/15, Average loss: 0.0010\n",
      "Epoch: 4/15, Average loss: 0.0010\n",
      "Epoch: 5/15, Average loss: 0.0010\n",
      "Epoch: 6/15, Average loss: 0.0009\n",
      "Epoch: 7/15, Average loss: 0.0009\n",
      "Epoch: 8/15, Average loss: 0.0009\n",
      "Epoch: 9/15, Average loss: 0.0009\n",
      "Epoch: 10/15, Average loss: 0.0009\n",
      "Epoch: 11/15, Average loss: 0.0009\n",
      "Epoch: 12/15, Average loss: 0.0009\n",
      "Epoch: 13/15, Average loss: 0.0008\n",
      "Epoch: 14/15, Average loss: 0.0008\n",
      "Training completed. Final training loss: 0.0008423349551856517, Validation loss: 0.00084237618483603\n"
     ]
    }
   ],
   "source": [
    "# 6 hidden layers\n",
    "learning_rate = 1e-5\n",
    "my_model = AE_0(input_dim=input_dim, latent_dim=8, decrease_rate=0.6, device=device, hidden_layers=6, output_activation_encoder=nn.Sigmoid, output_activation_decoder=None).to(device)\n",
    "writer = SummaryWriter(log_dir='/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/runs/MNIST/ld8_ep15_dr06_lr1e5_opeSigm_6hl')\n",
    "optimizer = optim.Adam(my_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "train(my_model, writer=writer, train_loader=train_loader, val_loader=val_loader, optimizer=optimizer, epochs=15)\n",
    "torch.save(my_model.state_dict(), '/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/models/MNIST/ld8_ep15_dr06_lr1e5_opeSigm_6hl.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6d5541c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/15, Average loss: 0.0013\n",
      "Epoch: 1/15, Average loss: 0.0011\n",
      "Epoch: 2/15, Average loss: 0.0011\n",
      "Epoch: 3/15, Average loss: 0.0011\n",
      "Epoch: 4/15, Average loss: 0.0011\n",
      "Epoch: 5/15, Average loss: 0.0011\n",
      "Epoch: 6/15, Average loss: 0.0011\n",
      "Epoch: 7/15, Average loss: 0.0011\n",
      "Epoch: 8/15, Average loss: 0.0011\n",
      "Epoch: 9/15, Average loss: 0.0011\n",
      "Epoch: 10/15, Average loss: 0.0011\n",
      "Epoch: 11/15, Average loss: 0.0011\n",
      "Epoch: 12/15, Average loss: 0.0011\n",
      "Epoch: 13/15, Average loss: 0.0011\n",
      "Epoch: 14/15, Average loss: 0.0011\n",
      "Training completed. Final training loss: 0.001051405894694229, Validation loss: 0.001059711416810751\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 7 hidden layers\n",
    "\n",
    "learning_rate = 1e-5\n",
    "\n",
    "my_model = AE_0(input_dim=input_dim, latent_dim=8, decrease_rate=0.6, device=device, hidden_layers=7, output_activation_encoder=nn.Sigmoid, output_activation_decoder=None).to(device)\n",
    "writer = SummaryWriter(log_dir='/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/runs/MNIST/ld8_ep15_dr06_lr1e5_slr5_01_opeSigm_7hl')\n",
    "optimizer = optim.Adam(my_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "train(my_model, writer=writer, train_loader=train_loader, val_loader=val_loader, optimizer=optimizer, epochs=15, scheduler=scheduler)\n",
    "torch.save(my_model.state_dict(), '/Users/enricofrausin/Programmazione/PythonProjects/Tesi/Autoencoders/models/MNIST/ld8_ep15_dr06_lr1e5_slr5_01_opeSigm_7hl.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "96c313a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_original_vs_decoded(my_model, train_loader, device=device, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108cf897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
